{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretability for Amharic NER\n",
    "This notebook demonstrates how to use SHAP and LIME to interpret NER model predictions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import shap\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from src.utils.ner_data_utils import parse_conll, build_label_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load model and tokenizer\n",
    "MODEL_DIR = 'notebooks/amharicnermodel'  # Adjust as needed\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_DIR)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load and inspect example data\n",
    "conll_path = '../data/raw/labeled_cnll_manual.txt'\n",
    "sentences, ner_tags = parse_conll(conll_path)\n",
    "label2id, id2label = build_label_maps(ner_tags)\n",
    "examples = [' '.join(sent) for sent in sentences[:5]]\n",
    "print('Examples:', examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prediction wrapper for SHAP/LIME\n",
    "def predict_proba(texts):\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    if not isinstance(texts, list):\n",
    "        texts = list(texts)\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, is_split_into_words=False)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "        probs = torch.softmax(outputs, dim=-1).cpu().numpy()\n",
    "    results = []\n",
    "    for i, text in enumerate(texts):\n",
    "        token_ids = inputs['input_ids'][i]\n",
    "        tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        word_ids = inputs.word_ids(batch_index=i)\n",
    "        mask = []\n",
    "        seen = set()\n",
    "        for idx, wid in enumerate(word_ids):\n",
    "            if wid is not None and wid not in seen:\n",
    "                mask.append(idx)\n",
    "                seen.add(wid)\n",
    "        results.append(probs[i][mask])\n",
    "    avg_probs = [np.mean(r, axis=0) for r in results]\n",
    "    return np.array(avg_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SHAP Explanation\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "explainer = shap.Explainer(predict_proba, tokenizer)\n",
    "shap_values = explainer(examples)\n",
    "for i, example in enumerate(examples):\n",
    "    shap.plots.text(shap_values[i], display=False)\n",
    "    plt.savefig(f'./results/shap_text_{i}.png')\n",
    "    plt.close()\n",
    "print('SHAP text plots saved for each example in ./results/')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# LIME Explanation\n",
    "class_names = list(label2id.keys())\n",
    "lime_explainer = LimeTextExplainer(class_names=class_names)\n",
    "for i, example in enumerate(examples):\n",
    "    exp = lime_explainer.explain_instance(\n",
    "        example,\n",
    "        predict_proba,\n",
    "        num_features=10,\n",
    "        num_samples=100\n",
    "    )\n",
    "    exp.save_to_file(f'./results/lime_explanation_{i}.html')\n",
    "    print(f'LIME explanation for example {i} saved to ./results/lime_explanation_{i}.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
